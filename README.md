# Deep Convolutional Generative Adversarial Network (DCGAN)

æ•µå¯¾çš„ç”Ÿæˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆGANï¼‰ã‚’ä½¿ç”¨ã—ãŸç”»åƒç”Ÿæˆã®å®Ÿè£…ã§ã™ã€‚ç”Ÿæˆå™¨ï¼ˆGeneratorï¼‰ã¨è­˜åˆ¥å™¨ï¼ˆDiscriminatorï¼‰ã‚’ç«¶ã‚ã›ã‚‹ã“ã¨ã§ã€ãƒªã‚¢ãƒ«ãªç”»åƒã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚

## ğŸ“‹ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

### GAN (Generative Adversarial Network) ã¨ã¯

GANã¯äºŒã¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒç«¶ã„åˆã†ã“ã¨ã§å­¦ç¿’ã‚’é€²ã‚ã‚‹ä»•çµ„ã¿ã§ã™ï¼š

- **ç”Ÿæˆå™¨ (Generator, G)**: ãƒã‚¤ã‚ºã‹ã‚‰å½ã®ç”»åƒã‚’ç”Ÿæˆ
- **è­˜åˆ¥å™¨ (Discriminator, D)**: æœ¬ç‰©ã¨å½ç‰©ã‚’åŒºåˆ¥

### DCGAN ã®ç‰¹å¾´

**DCGAN (Deep Convolutional GAN)** ã¯ã€GANã«ç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆCNNï¼‰ã‚’çµ„ã¿åˆã‚ã›ãŸãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚

**ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ç‰¹å¾´:**
- ç”Ÿæˆå™¨: è»¢ç½®ç•³ã¿è¾¼ã¿å±¤ã‚’ä½¿ç”¨ã—ã¦ãƒ†ãƒ³ã‚½ãƒ«ã‚’æ‹¡å¤§
- è­˜åˆ¥å™¨: é€šå¸¸ã®ç•³ã¿è¾¼ã¿å±¤ã‚’ä½¿ç”¨ã—ã¦ç‰¹å¾´æŠ½å‡º
- ãƒãƒƒãƒæ­£è¦åŒ–ï¼ˆBatch Normalizationï¼‰ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®‰å®šåŒ–
- LeakyReLUã‚’ä½¿ç”¨ã—ãŸæ´»æ€§åŒ–é–¢æ•°

## ğŸ”¬ æ•°å­¦çš„åŸºç¤

### GAN ã®æå¤±é–¢æ•°

è­˜åˆ¥å™¨ã¨ç”Ÿæˆå™¨ã¯ãƒŸãƒ‹ãƒãƒƒã‚¯ã‚¹ã‚²ãƒ¼ãƒ ã‚’ãƒ—ãƒ¬ã‚¤ã—ã¾ã™ï¼š

$$\min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{\text{data}}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]$$

ã“ã“ã§ï¼š
- $x$: æœ¬ç‰©ã®ç”»åƒ
- $z$: ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚º
- $D(x)$: è­˜åˆ¥å™¨ã®å‡ºåŠ›ï¼ˆæœ¬ç‰©ã§ã‚ã‚‹ç¢ºç‡ï¼‰
- $G(z)$: ç”Ÿæˆå™¨ã®å‡ºåŠ›ï¼ˆç”Ÿæˆç”»åƒï¼‰

### è¨“ç·´ãƒ—ãƒ­ã‚»ã‚¹

**1. è­˜åˆ¥å™¨ã®æ›´æ–°**
$$\nabla_D \left[ \mathbb{E}_x[\log D(x)] + \mathbb{E}_z[\log(1 - D(G(z)))] \right]$$

**2. ç”Ÿæˆå™¨ã®æ›´æ–°**
$$\nabla_G \mathbb{E}_z[\log(1 - D(G(z)))]$$

ã¾ãŸã¯å®Ÿå‹™ã§ã¯ä»¥ä¸‹ã‚’ä½¿ç”¨ï¼ˆã‚ˆã‚Šå®‰å®šï¼‰ï¼š
$$\nabla_G \mathbb{E}_z[-\log D(G(z))]$$

## ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ç”Ÿæˆå™¨ (Generator)

```
å…¥åŠ›: ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚º z (100æ¬¡å…ƒ)
  â†“
å…¨çµåˆå±¤ â†’ 4Ã—4Ã—512
  â†“
è»¢ç½®ç•³ã¿è¾¼ã¿å±¤ + BatchNorm + ReLU (4Ã—4â†’8Ã—8)
  â†“
è»¢ç½®ç•³ã¿è¾¼ã¿å±¤ + BatchNorm + ReLU (8Ã—8â†’16Ã—16)
  â†“
è»¢ç½®ç•³ã¿è¾¼ã¿å±¤ + BatchNorm + ReLU (16Ã—16â†’32Ã—32)
  â†“
è»¢ç½®ç•³ã¿è¾¼ã¿å±¤ + Tanh (32Ã—32â†’64Ã—64)
  â†“
å‡ºåŠ›: ç”Ÿæˆç”»åƒ (64Ã—64Ã—3)
```

### è­˜åˆ¥å™¨ (Discriminator)

```
å…¥åŠ›: ç”»åƒ (64Ã—64Ã—3)
  â†“
ç•³ã¿è¾¼ã¿å±¤ + LeakyReLU (64Ã—64â†’32Ã—32)
  â†“
ç•³ã¿è¾¼ã¿å±¤ + BatchNorm + LeakyReLU (32Ã—32â†’16Ã—16)
  â†“
ç•³ã¿è¾¼ã¿å±¤ + BatchNorm + LeakyReLU (16Ã—16â†’8Ã—8)
  â†“
ç•³ã¿è¾¼ã¿å±¤ + BatchNorm + LeakyReLU (8Ã—8â†’4Ã—4)
  â†“
å…¨çµåˆå±¤
  â†“
å‡ºåŠ›: ã‚¹ã‚«ãƒ©ãƒ¼å€¤ (æœ¬ç‰©ã§ã‚ã‚‹ç¢ºç‡)
```

## ğŸš€ ä¸»ãªæ‰‹æ³•ã¨å·¥å¤«

| æ‰‹æ³• | èª¬æ˜ |
|------|------|
| **Batch Normalization** | å„å±¤ã®å…¥åŠ›ã‚’æ­£è¦åŒ–ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®‰å®šåŒ– |
| **LeakyReLU** | è­˜åˆ¥å™¨ã§ä½¿ç”¨ã€‚è² ã®é ˜åŸŸã§ã‚‚ã‚°ãƒ©ãƒ‡ãƒ¼ãƒ³ãƒˆãŒæµã‚Œã‚‹ |
| **Transposed Convolution** | ç”Ÿæˆå™¨ã§ä½¿ç”¨ã€‚ãƒ†ãƒ³ã‚½ãƒ«ã‚’æ‹¡å¤§ |
| **Label Smoothing** | éå­¦ç¿’ã‚’é˜²æ­¢ã™ã‚‹ãŸã‚ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ©ãƒ™ãƒ«ã‚’å¹³æ»‘åŒ– |
| **Spectral Normalization** | è­˜åˆ¥å™¨ã®é‡ã¿ã‚’æ­£è¦åŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ |

## ğŸ“Š è¨“ç·´æ›²ç·šã®ä¾‹

```
Discriminator Loss        Generator Loss
      â”‚                        â”‚
      â”‚  â•±â•²â•±â•²                  â”‚  â•±â”€â”€
      â”‚â•±â•²â•±â•²â•±                   â”‚â•±
      â”‚                        â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€
         è¨“ç·´ã‚¨ãƒãƒƒã‚¯æ•°
```

- è¨“ç·´åˆæœŸ: ç”Ÿæˆå™¨ãŒè²§å¼±ãªãŸã‚ã€è­˜åˆ¥å™¨ã¯ç°¡å˜ã«åˆ¤åˆ¥
- è¨“ç·´ä¸­ç›¤: ç”Ÿæˆå™¨ãŒä¸Šé”ã—ã€æå¤±ãŒæŒ¯å‹•
- è¨“ç·´å¾ŒæœŸ: ä¸¡æ–¹ãŒå‡è¡¡ã‚’å–ã‚Šã€ãƒªã‚¢ãƒ«ãªç”»åƒç”Ÿæˆ

## ğŸ’¾ ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

```
Deep_Convolutional_GAN/
â”œâ”€â”€ README.md                 # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ dcgan.py                  # DCGANå®Ÿè£…ï¼ˆãƒ¢ãƒ‡ãƒ«å®šç¾©ï¼‰
â”œâ”€â”€ train.py                  # è¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ requirements.txt          # å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª
â”œâ”€â”€ checkpoints/              # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¿å­˜ç”¨
â””â”€â”€ outputs/                  # ç”Ÿæˆç”»åƒä¿å­˜ç”¨
```

## âš™ï¸ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/YourUsername/Deep_Convolutional_GAN.git
cd Deep_Convolutional_GAN

# ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt
```

### å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª

- PyTorch >= 1.9.0
- torchvision >= 0.10.0
- numpy
- matplotlib
- Pillow

## ğŸ¯ ä½¿ç”¨æ–¹æ³•

### ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´

```bash
python train.py \
    --dataset cifar10 \
    --batch_size 128 \
    --num_epochs 100 \
    --learning_rate 0.0002 \
    --save_interval 10
```

#### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | èª¬æ˜ |
|----------|---------|------|
| `--dataset` | cifar10 | ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ |
| `--batch_size` | 128 | ãƒãƒƒãƒã‚µã‚¤ã‚º |
| `--num_epochs` | 100 | è¨“ç·´ã‚¨ãƒãƒƒã‚¯æ•° |
| `--learning_rate` | 0.0002 | Adamæœ€é©åŒ–å™¨ã®å­¦ç¿’ç‡ |
| `--beta1` | 0.5 | Adamã®ç¬¬1ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆä¿‚æ•° |
| `--save_interval` | 10 | ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã®é–“éš”ï¼ˆã‚¨ãƒãƒƒã‚¯ï¼‰ |
| `--device` | cuda | è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹ï¼ˆcuda/cpuï¼‰ |

### ç”Ÿæˆç”»åƒã®ç¢ºèª

```python
from dcgan import Generator
import torch
from torchvision.utils import save_image

# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
gen = Generator().to(device)
gen.load_state_dict(torch.load('checkpoints/generator_epoch_50.pth'))
gen.eval()

# ç”»åƒç”Ÿæˆ
with torch.no_grad():
    z = torch.randn(16, 100, 1, 1, device=device)
    fake_images = gen(z)
    save_image(fake_images, 'generated_images.png', normalize=True)
```

## ğŸ“ˆ è¨“ç·´çµæœã®å¯è¦–åŒ–

```python
import matplotlib.pyplot as plt

# è¨“ç·´ãƒ­ã‚°ã‚’èª­ã¿è¾¼ã¿
d_losses = [...]  # è­˜åˆ¥å™¨ã®æå¤±
g_losses = [...]  # ç”Ÿæˆå™¨ã®æå¤±

plt.figure(figsize=(10, 5))
plt.plot(d_losses, label='Discriminator Loss')
plt.plot(g_losses, label='Generator Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.savefig('training_loss.png')
plt.show()
```

## ğŸ” å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ

### 1. é‡ã¿åˆæœŸåŒ–

```python
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)
        torch.nn.init.constant_(m.bias.data, 0)
```

### 2. æå¤±é–¢æ•°

è­˜åˆ¥å™¨ã¨ç”Ÿæˆå™¨ã§ç•°ãªã‚‹æå¤±é–¢æ•°ã‚’ä½¿ç”¨ï¼š

```python
# è­˜åˆ¥å™¨
loss_fn = nn.BCELoss()

# è­˜åˆ¥å™¨ã®æå¤±
d_loss = loss_fn(D(real_images), real_labels) + \
         loss_fn(D(fake_images.detach()), fake_labels)

# ç”Ÿæˆå™¨ã®æå¤±
g_loss = loss_fn(D(fake_images), real_labels)
```

### 3. è¨“ç·´ãƒ«ãƒ¼ãƒ—

- è­˜åˆ¥å™¨ã‚’è¤‡æ•°å›æ›´æ–°ã—ã¦ã‹ã‚‰ç”Ÿæˆå™¨ã‚’æ›´æ–°
- ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æ¶ˆå¤±ã‚’é˜²ããŸã‚ã€ç”Ÿæˆå™¨ã®æå¤±è¨ˆç®—æ™‚ã«Detach()ã‚’æ´»ç”¨
- å®šæœŸçš„ã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä¿å­˜

## ğŸ“š å‚è€ƒè³‡æ–™

- **å…ƒè«–æ–‡**: "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks" (Radford et al., 2015)
- **å‚è€ƒã‚¹ãƒ©ã‚¤ãƒ‰**: [ã‚¢ãƒ‰ãƒãƒ³ã‚¹ãƒˆãƒ“ã‚¸ãƒ§ãƒ³ç¬¬4å›](https://ryuichiueda.github.io/slides_marp/advanced_vision/lesson4.html)
- **PyTorchå…¬å¼ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«**: https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html

## ğŸ“ ç¿’å¾—ã§ãã‚‹å†…å®¹

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€šã˜ã¦ä»¥ä¸‹ã‚’å­¦ã¹ã¾ã™ï¼š

- âœ… æ•µå¯¾çš„ç”Ÿæˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ç†è«–ã¨å®Ÿè£…
- âœ… æ·±å±¤å­¦ç¿’ã«ãŠã‘ã‚‹ä¸å®‰å®šæ€§ã®å¯¾å‡¦æ³•
- âœ… PyTorchã‚’ä½¿ç”¨ã—ãŸè¤‡é›‘ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ§‹ç¯‰
- âœ… ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å‡¦ç†ã¨æ­£è¦åŒ–
- âœ… ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã€ä¿å­˜ã€å¾©å…ƒ
- âœ… ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡æ–¹æ³•

## âš ï¸ è¨“ç·´æ™‚ã®æ³¨æ„ç‚¹

1. **ãƒ¢ãƒ¼ãƒ‰å´©å£Š (Mode Collapse)**: ç”Ÿæˆå™¨ãŒé™å®šçš„ãªç¨®é¡ã®ç”»åƒã—ã‹ç”Ÿæˆã§ããªããªã‚‹ç¾è±¡
   - å¯¾ç­–: å­¦ç¿’ç‡ã®èª¿æ•´ã€æ–°ã—ã„æå¤±é–¢æ•°ï¼ˆWassersteinè·é›¢ï¼‰ã®ä½¿ç”¨

2. **å‹¾é…æ¶ˆå¤±**: ç”Ÿæˆå™¨ã®å‹¾é…ãŒæ¶ˆå¤±ã™ã‚‹å•é¡Œ
   - å¯¾ç­–: LeakyReLUã€Spectral Normalizationã®ä½¿ç”¨

3. **æŒ¯å‹•**: æå¤±ãŒåæŸã›ãšæŒ¯å‹•ã—ç¶šã‘ã‚‹
   - å¯¾ç­–: ãƒãƒƒãƒã‚µã‚¤ã‚ºã®èª¿æ•´ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ä¿®æ­£

## ğŸ“ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚

## ğŸ¤ è²¢çŒ®

æ”¹å–„ææ¡ˆã‚„ãƒã‚°å ±å‘Šã¯ã€Issuesã‚„ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
